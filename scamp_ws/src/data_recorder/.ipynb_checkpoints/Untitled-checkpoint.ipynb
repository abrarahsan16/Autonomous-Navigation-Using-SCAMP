{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.generic_utils import Progbar\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(ImageDataGenerator):\n",
    "    def flow_from_directory(self,directory, target_size=(244,244),crop_size=(250,250), color_mode='grayscale',\n",
    "                            batch_size=32, shuffle=True, seed=None, follow_links=False):\n",
    "        return DirectoryIterator(directory, self, target_size=target_size, crop_size = crop_size,\n",
    "                                     color_mode = color_mode, batch_size = batch_size, shuffle=shuffle, seed=seed, follow_links=follow_links)\n",
    "    \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectoryIterator(Iterator):\n",
    "    \"\"\"\n",
    "    Class for managing data loading.of images and labels\n",
    "    We assume that the folder structure is:\n",
    "    root_folder/\n",
    "           folder_1/\n",
    "                    images/\n",
    "                    sync_steering.txt or labels.txt\n",
    "           folder_2/\n",
    "                    images/\n",
    "                    sync_steering.txt or labels.txt\n",
    "           .\n",
    "           .\n",
    "           folder_n/\n",
    "                    images/\n",
    "                    sync_steering.txt or labels.txt\n",
    "    # Arguments\n",
    "       directory: Path to the root directory to read data from.\n",
    "       image_data_generator: Image Generator.\n",
    "       target_size: tuple of integers, dimensions to resize input images to.\n",
    "       crop_size: tuple of integers, dimensions to crop input images.\n",
    "       color_mode: One of `\"rgb\"`, `\"grayscale\"`. Color mode to read images.\n",
    "       batch_size: The desired batch size\n",
    "       shuffle: Whether to shuffle data or not\n",
    "       seed : numpy seed to shuffle data\n",
    "       follow_links: Bool, whether to follow symbolic links or not\n",
    "    # TODO: Add functionality to save images to have a look at the augmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, image_data_generator,\n",
    "            target_size=(224,224), crop_size = (250,250), color_mode='grayscale',\n",
    "            batch_size=32, shuffle=True, seed=None, follow_links=False):\n",
    "        self.directory = directory\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.target_size = tuple(target_size)\n",
    "        self.crop_size = tuple(crop_size)\n",
    "        self.follow_links = follow_links\n",
    "        if color_mode not in {'rgb', 'grayscale'}:\n",
    "            raise ValueError('Invalid color mode:', color_mode,\n",
    "                             '; expected \"rgb\" or \"grayscale\".')\n",
    "        self.color_mode = color_mode\n",
    "        if self.color_mode == 'rgb':\n",
    "            self.image_shape = self.crop_size + (3,)\n",
    "        else:\n",
    "            self.image_shape = self.crop_size + (1,)\n",
    "\n",
    "        # First count how many experiments are out there\n",
    "        self.samples = 0\n",
    "\n",
    "        experiments = []\n",
    "        for subdir in sorted(os.listdir(directory)):\n",
    "            if os.path.isdir(os.path.join(directory, subdir)):\n",
    "                experiments.append(subdir)\n",
    "        self.num_experiments = len(experiments)\n",
    "        self.formats = {'png', 'jpg'}\n",
    "\n",
    "        # Idea = associate each filename with a corresponding steering or label\n",
    "        self.filenames = []\n",
    "        self.ground_truth = []\n",
    "\n",
    "        # Determine the type of experiment (steering or collision) to compute\n",
    "        # the loss\n",
    "        self.exp_type = []\n",
    "\n",
    "        for subdir in experiments:\n",
    "            subpath = os.path.join(directory, subdir)\n",
    "            self._decode_experiment_dir(subpath)\n",
    "\n",
    "        # Conversion of list into array\n",
    "        self.ground_truth = np.array(self.ground_truth, dtype = K.floatx())\n",
    "\n",
    "        assert self.samples > 0, \"Did not find any data\"\n",
    "\n",
    "        print('Found {} images belonging to {} experiments.'.format(\n",
    "                self.samples, self.num_experiments))\n",
    "        super(DroneDirectoryIterator, self).__init__(self.samples,\n",
    "                batch_size, shuffle, seed)\n",
    "\n",
    "    def _recursive_list(self, subpath):\n",
    "        return sorted(os.walk(subpath, followlinks=self.follow_links),\n",
    "                key=lambda tpl: tpl[0])\n",
    "\n",
    "    def _decode_experiment_dir(self, dir_subpath):\n",
    "        # Load steerings or labels in the experiment dir\n",
    "        steerings_filename = os.path.join(dir_subpath, \"Velocity.csv\")\n",
    "        labels_filename = os.path.join(dir_subpath, \"labels.txt\")\n",
    "\n",
    "        # Try to load steerings first. Make sure that the steering angle or the\n",
    "        # label file is in the first column. Note also that the first line are\n",
    "        # comments so it should be skipped.\n",
    "        try:\n",
    "            ground_truth = np.loadtxt(steerings_filename, usecols=0,\n",
    "                                  delimiter=',', skiprows=1)\n",
    "            exp_type = 1\n",
    "        except OSError as e:\n",
    "            # Try load collision labels if there are no steerings\n",
    "            try:\n",
    "                ground_truth = np.loadtxt(labels_filename, usecols=0)\n",
    "                exp_type = 0\n",
    "            except OSError as e:\n",
    "                print(\"Neither steerings nor labels found in dir {}\".format(\n",
    "                dir_subpath))\n",
    "                raise IOError\n",
    "\n",
    "\n",
    "        # Now fetch all images in the image subdir\n",
    "        image_dir_path = os.path.join(dir_subpath, \"images\")\n",
    "        for root, _, files in self._recursive_list(image_dir_path):\n",
    "            sorted_files = sorted(files,\n",
    "                    key = lambda fname: int(re.search(r'\\d+',fname).group()))\n",
    "            for frame_number, fname in enumerate(sorted_files):\n",
    "                is_valid = False\n",
    "                for extension in self.formats:\n",
    "                    if fname.lower().endswith('.' + extension):\n",
    "                        is_valid = True\n",
    "                        break\n",
    "                if is_valid:\n",
    "                    absolute_path = os.path.join(root, fname)\n",
    "                    self.filenames.append(os.path.relpath(absolute_path,\n",
    "                            self.directory))\n",
    "                    self.ground_truth.append(ground_truth[frame_number])\n",
    "                    self.exp_type.append(exp_type)\n",
    "                    self.samples += 1\n",
    "\n",
    "\n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        return self._get_batches_of_transformed_samples(index_array)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array) :\n",
    "        \"\"\"\n",
    "        Public function to fetch next batch.\n",
    "        # Returns\n",
    "            The next batch of images and labels.\n",
    "        \"\"\"\n",
    "        current_batch_size = index_array.shape[0]\n",
    "        # Image transformation is not under thread lock, so it can be done in\n",
    "        # parallel\n",
    "        batch_x = np.zeros((current_batch_size,) + self.image_shape,\n",
    "                dtype=K.floatx())\n",
    "        batch_steer = np.zeros((current_batch_size, 2,),\n",
    "                dtype=K.floatx())\n",
    "        batch_coll = np.zeros((current_batch_size, 2,),\n",
    "                dtype=K.floatx())\n",
    "\n",
    "        grayscale = self.color_mode == 'grayscale'\n",
    "\n",
    "        # Build batch of image data\n",
    "        for i, j in enumerate(index_array):\n",
    "            fname = self.filenames[j]\n",
    "            x = img_utils.load_img(os.path.join(self.directory, fname),\n",
    "                    grayscale=grayscale,\n",
    "                    crop_size=self.crop_size,\n",
    "                    target_size=self.target_size)\n",
    "\n",
    "            x = self.image_data_generator.random_transform(x)\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "\n",
    "            # Build batch of steering and collision data\n",
    "            if self.exp_type[index_array[i]] == 1:\n",
    "                # Steering experiment (t=1)\n",
    "                batch_steer[i,0] =1.0\n",
    "                batch_steer[i,1] = self.ground_truth[index_array[i]]\n",
    "                batch_coll[i] = np.array([1.0, 0.0])\n",
    "            else:\n",
    "                # Collision experiment (t=0)\n",
    "                batch_steer[i] = np.array([0.0, 0.0])\n",
    "                batch_coll[i,0] = 0.0\n",
    "                batch_coll[i,1] = self.ground_truth[index_array[i]]\n",
    "\n",
    "        batch_y = [batch_steer, batch_coll]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = DataGenerator(rotation_range = 0.2,\n",
    "                                             rescale = 1./255,\n",
    "                                             width_shift_range = 0.2,\n",
    "                                             height_shift_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neither steerings nor labels found in dir /home/abrarahsan16/SCAMP/Autonomous-Navigation-Using-SCAMP/scamp_ws/src/data_recorder/.ipynb_checkpoints\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bb6999f6111c>\u001b[0m in \u001b[0;36m_decode_experiment_dir\u001b[0;34m(self, dir_subpath)\u001b[0m\n\u001b[1;32m     91\u001b[0m             ground_truth = np.loadtxt(steerings_filename, usecols=0,\n\u001b[0;32m---> 92\u001b[0;31m                                   delimiter=',', skiprows=1)\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mexp_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abrarahsan16/.local/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abrarahsan16/.local/lib/python3.5/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abrarahsan16/.local/lib/python3.5/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /home/abrarahsan16/SCAMP/Autonomous-Navigation-Using-SCAMP/scamp_ws/src/data_recorder/.ipynb_checkpoints/Velocity.csv not found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bb6999f6111c>\u001b[0m in \u001b[0;36m_decode_experiment_dir\u001b[0;34m(self, dir_subpath)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0mexp_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abrarahsan16/.local/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abrarahsan16/.local/lib/python3.5/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abrarahsan16/.local/lib/python3.5/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /home/abrarahsan16/SCAMP/Autonomous-Navigation-Using-SCAMP/scamp_ws/src/data_recorder/.ipynb_checkpoints/labels.txt not found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f42fdf958f8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                         \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                         batch_size = 32)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-7ab92b834bfc>\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, crop_size, color_mode, batch_size, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m      3\u001b[0m                             batch_size=32, shuffle=True, seed=None, follow_links=False):\n\u001b[1;32m      4\u001b[0m         return DirectoryIterator(directory, self, target_size=target_size, crop_size = crop_size,\n\u001b[0;32m----> 5\u001b[0;31m                                      color_mode = color_mode, batch_size = batch_size, shuffle=shuffle, seed=seed, follow_links=follow_links)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-bb6999f6111c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, crop_size, color_mode, batch_size, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0msubpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode_experiment_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Conversion of list into array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-bb6999f6111c>\u001b[0m in \u001b[0;36m_decode_experiment_dir\u001b[0;34m(self, dir_subpath)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 print(\"Neither steerings nor labels found in dir {}\".format(\n\u001b[1;32m    101\u001b[0m                 dir_subpath))\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory = \"/home/abrarahsan16/SCAMP/Autonomous-Navigation-Using-SCAMP/scamp_ws/src/data_recorder/data\",\n",
    "                                                        shuffle = True,\n",
    "                                                        color_mode=\"grayscale\",\n",
    "                                                        target_size=(640, 480),\n",
    "                                                        crop_size=(250, 250),\n",
    "                                                        batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
